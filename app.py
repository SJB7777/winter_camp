from flask import Flask, request, jsonify
import matplotlib
matplotlib.use('Agg') # Server-side rendering
import torch
import numpy as np
import pandas as pd
import json
import os

# --- Core Modules (Shared with Debug Pipeline) ---
from src.refine import refine_with_gradient
from src.abeles import AbelesMatrix
from src.physics_utils import tth2q
from src.config import CONFIG, XRefineConfig
from src.nn_glue import load_model_from_checkpoint, predict_initial_params
from src.data_processing import apply_anchor_normalization
from src.simulation import simulate_reflectivity
from src.visualization import plot_fit_result

app = Flask(__name__)

# ==============================================================================
# 0. Global Setup
# ==============================================================================
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
PHYSICS_ENGINE = AbelesMatrix(device=DEVICE)

# Config Load
config_path = "config.yaml"
if os.path.exists(config_path):
    print(f"ğŸ“‚ Server Config Loaded: {config_path}")
    real_config = XRefineConfig.load_yaml(config_path)
    CONFIG.sample = real_config.sample
    CONFIG.instrument = real_config.instrument

# AI Model Load
ckpt_path = os.environ.get("MODEL_PATH", "checkpoints/model.pt")
AI_MODEL = None
if os.path.exists(ckpt_path):
    AI_MODEL, _ = load_model_from_checkpoint(ckpt_path, DEVICE)
    print("âœ… AI Model Ready.")
else:
    print(f"âš ï¸ Model not found at {ckpt_path}")

# ==============================================================================
# 1. Simulator Interface
# ==============================================================================
def simulator_wrapper(param_tensors: dict[str, torch.Tensor], q_tensor: torch.Tensor) -> torch.Tensor:
    """
    Refine Engineì´ í˜¸ì¶œí•˜ëŠ” í‘œì¤€ ì¸í„°í˜ì´ìŠ¤.
    src.simulation.simulate_reflectivityë¡œ ìœ„ì„í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì½”ë“œì™€ 100% ë™ì¼ ë¡œì§ ë³´ì¥.
    """
    return simulate_reflectivity(param_tensors, q_tensor, PHYSICS_ENGINE, DEVICE)

# ==============================================================================
# 2. API Routes
# ==============================================================================

@app.route('/predict_initial', methods=['POST'])
def api_predict_initial():
    """
    [Step 1] ë°ì´í„° ë¡œë“œ -> ì •ê·œí™” -> AI ì´ˆì•ˆ -> ê·¸ë˜í”„(Base64)
    """
    try:
        if 'file' not in request.files: 
            return jsonify({"error": "No file uploaded"}), 400
        
        file = request.files['file']
        
        # 1. Load Data
        df = pd.read_csv(file, sep=r'\s+', comment='#', header=None, dtype=str)
        df = df.replace({r'[()]': ''}, regex=True).astype(float).dropna()
        x_raw, y_raw = df.iloc[:, 0].values, df.iloc[:, 1].values
        
        # 2. Apply Anchor Normalization (Core Logic)
        q_vals = tth2q(x_raw, wavelen=CONFIG.instrument.wavelength)
        y_norm, scale_factor = apply_anchor_normalization(
            q_vals, y_raw, CONFIG.instrument.wavelength
        )
        
        # Prepare Tensors
        q_tensor = torch.from_numpy(q_vals).float().to(DEVICE)
        # AI ì…ë ¥ë„ ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ ì‚¬ìš© (log10)
        log_r_obs = torch.log10(torch.clamp(torch.from_numpy(y_norm).float().to(DEVICE), min=1e-12))
        
        # 3. AI Prediction
        initial_params = {}
        if AI_MODEL:
            try:
                initial_params = predict_initial_params(AI_MODEL, q_tensor, log_r_obs, DEVICE)
            except Exception as e:
                print(f"AI Prediction Failed: {e}")
        
        # Fallback Defaults
        if not initial_params:
            initial_params = {"i0": 1.0, "bkg": -6.0}
            for l in CONFIG.sample.layers:
                initial_params[f"{l.name}.thickness"] = 300.0
                initial_params[f"{l.name}.roughness"] = 3.0
                initial_params[f"{l.name}.sld"] = 50.0
                initial_params[f"{l.name}.sld_imag"] = 1.0
            initial_params["Substrate.roughness"] = 2.0
            initial_params["Substrate.sld"] = 20.0
            initial_params["Substrate.sld_imag"] = 0.0

        # [SCALE LOCK] ì •ê·œí™”ë˜ì—ˆìœ¼ë¯€ë¡œ i0ëŠ” 1.0 ê°•ì œ
        initial_params['i0'] = 1.0

        # 4. Simulate & Plot (Normalized View)
        with torch.no_grad():
            p_tensors = {k: torch.tensor([v], device=DEVICE) for k, v in initial_params.items()}
            r_sim = simulator_wrapper(p_tensors, q_tensor).cpu().numpy().flatten()
            
            # src.visualization ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± (Base64 ë¦¬í„´)
            plot_base64 = plot_fit_result(
                q_vals, y_norm, r_sim, 
                title="Step 1: AI Initial Guess (Normalized)",
                save_path=None # Noneì´ë©´ Base64 ë¬¸ìì—´ ë°˜í™˜
            )

        return jsonify({
            "status": "success",
            "initial_params": initial_params,
            "valid_keys": list(initial_params.keys()),
            "scale_factor": float(scale_factor), # í´ë¼ì´ì–¸íŠ¸ì— ìŠ¤ì¼€ì¼ ì •ë³´ ì œê³µ
            "plot_base64": plot_base64
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/refine_gradient', methods=['POST'])
def api_refine():
    """
    [Step 2] í˜„ì¬ íŒŒë¼ë¯¸í„° + ì˜µì…˜ -> Optimizer ì‹¤í–‰ -> ê²°ê³¼ & ê·¸ë˜í”„
    """
    try:
        # Input Parsing
        file = request.files['file']
        current_params = json.loads(request.form.get('current_params', '{}'))
        optimize_spec = json.loads(request.form.get('optimize_spec', '{}'))
        
        # 1. Load & Normalize (Same as Step 1)
        df = pd.read_csv(file, sep=r'\s+', comment='#', header=None, dtype=str)
        df = df.replace({r'[()]': ''}, regex=True).astype(float).dropna()
        x_raw, y_raw = df.iloc[:, 0].values, df.iloc[:, 1].values
        
        q_vals = tth2q(x_raw, wavelen=CONFIG.instrument.wavelength)
        y_norm, _ = apply_anchor_normalization(
            q_vals, y_raw, CONFIG.instrument.wavelength
        )
        
        q_tensor = torch.from_numpy(q_vals).float().to(DEVICE)
        y_tensor = torch.from_numpy(y_norm).float().to(DEVICE)
        log_r_obs = torch.log10(torch.clamp(y_tensor, min=1e-12))
        
        data_payload = {'q': q_tensor, 'log_r_obs': log_r_obs}
        
        # [Safety Guard] i0 Bounds Check
        # í´ë¼ì´ì–¸íŠ¸ê°€ i0 ë²”ìœ„ë¥¼ ë„ˆë¬´ ë„“ê²Œ ì¡ì•˜ì„ ê²½ìš° ì„œë²„ì—ì„œ ì•ˆì „í•˜ê²Œ í´ë¨í•‘
        if 'target_params' in optimize_spec and 'i0' in optimize_spec['target_params']:
            bounds = optimize_spec['target_params']['i0']
            # i0ëŠ” 1.0 ê·¼ì²˜ì—¬ì•¼ í•¨ (0.8 ~ 1.2)
            safe_min = max(bounds[0], 0.8)
            safe_max = min(bounds[1], 1.2)
            optimize_spec['target_params']['i0'] = [safe_min, safe_max]
            print(f"ğŸ”’ Server enforced i0 bounds: [{safe_min}, {safe_max}]")

        # 2. Run Refinement
        print(f"ğŸ”¥ Starting Refinement ({optimize_spec.get('loss_type', 'LogMSE')})...")
        refined_params, final_loss = refine_with_gradient(
            current_params, data_payload, optimize_spec, simulator_wrapper, DEVICE
        )
        print(f"âœ… Refinement Done. Loss: {final_loss:.6f}")
        
        # 3. Plot Result (Normalized View)
        with torch.no_grad():
            # Initial Curve (Comparison)
            p_init = {k: torch.tensor([v], device=DEVICE) for k, v in current_params.items()}
            # Refined Curve
            p_ref = {k: torch.tensor([v], device=DEVICE) for k, v in refined_params.items()}
            
            r_final = simulator_wrapper(p_ref, q_tensor).cpu().numpy().flatten()
            
            # ê·¸ë˜í”„ ìƒì„±
            loss_name = optimize_spec.get('loss_type', 'LogMSE')
            plot_base64 = plot_fit_result(
                q_vals, y_norm, r_final, 
                title=f"Refined Result ({loss_name}) | Loss: {final_loss:.4f}",
                save_path=None
            )
            
        return jsonify({
            "status": "success",
            "updated_params": refined_params,
            "final_loss": final_loss,
            "plot_base64": plot_base64
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    # Production Level: 0.0.0.0 for external access
    app.run(host='0.0.0.0', port=5000, debug=False)